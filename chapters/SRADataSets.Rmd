```{r internal_functions, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
## Prereqs
# Enable caching
knitr::opts_chunk$set(cache=TRUE)

# libraries
library(pander)
library(GEOmetadb)
library(SRAdb)
library(png)
library(grid)

# functions
string.trim <- function(vstring, limit=60) {
  ## Given a vector of strings (i.e. column from a resultset), trim the string
  ## at length 'limit' and append a '...'.
  new.vector <- c()
  for (f in vstring) {
    if (!is.na(f) && nchar(f) != 0 && nchar(f) > limit)
      new.vector <- c(new.vector, paste0(strtrim(f, limit-3), '...'))
    else
      new.vector <- c(new.vector, f)
  }
  return(new.vector)
}

vector.to.table <- function(data, nrow, colname) {
  ## Splits a vector into columns for displaying in a Markdown file using 
  ## the 'pander' library. The 'nrow' argument is used as split index.
  ## The 'colname' argument is used to name the created columns
  table <- split(data, ceiling(seq_along(data)/nrow))
  table <- lapply(table, function(column) {
      # Check the number of rows in the column
      missing.elements <- nrow - length(column)
      if (missing.elements > 0)
        column <- c(column, rep('', missing.elements))
      else
        return(column)
    })

  max.rows <- max(unlist(lapply(table, FUN=length)))
  attributes(table) = list(names = rep(colname, length(table)),
    row.names=1:max.rows, class='data.frame')
  
  return(table)
}

## Week / chapter number
chapter <- 1
## Question number; global var updated with each question
n.q <- 0

insert.q <- function(q_string="") {
  ## Updates the question number each time a question is added
  n.q <<- n.q + 1
  if (q_string != "")
    cat(paste0("### Question ", chapter, ".", n.q, ": ", q_string))
  else
    cat(paste0("### Question ", chapter, ".", n.q))
}
```

# Discovering Data Sets {#chapter-3}

## Finding Public Data Sets of Interest {#finding-public-data}

This chapter describes multiple methods of finding public datasets of interest. A *dataset* in the context of the capstone project refers to all data belonging to a certain gene-expression experiment, usually consisting of a number of sequencing-samples combined with *meta-data* describing the experiment. 

There are a number of very large databases online that offer access to thousands of - published - experiments and here we will focus on searching and downloading gene expression data from high-throughput (`NGS`) sequencing techniques (`RNA-Seq`).

With thousands of freely available datasets it is possible to start performing research without the need of actually performing your own lab-experiment. For all common conditions, organisms and tissues you can download samples and compare them over multiple studies to find novel relations between genes and conditions or to verify experiments performed in your laboratory. For instance, the power of public datasets was recently demonstrated jointly by three of our alumni in an article called [*Calling genotypes from public RNA-sequencing data enables identification of genetic variants that affect gene-expression levels.*](http://www.ncbi.nlm.nih.gov/pubmed/25954321).

It's method section begins with the sentence "*We downloaded the raw reads for all available human RNA-seq datasets*" of which the amount of data and work will become clear later on. If you are interested in *expression Quantitative Trait Loci* (`eQTL`) or *Allele-Specific Expression* (`ASE`) analysis, please read this very interesting paper.

The following weeks you will be investigating one or more public RNA-sequencing datasets yourself and the rest of this document focuses on databases containing such public data sets and - especially - how to find a dataset or experiment you would like to use.

But before we start diving into large and complex databases potentially containing thousands of experiments with millions of samples and terabytes of data, we need to get a rough idea on what we would like to do once we have found something of interest in order to know what we are looking for in the first place. While there is no definitive guide or protocol that can be followed for processing and analysing a gene-expression dataset, the following goals can be considered:

1. Re-do (part of) the analysis described in the accompanying publication.
    * As all datasets -  except for the ones that were added very recently - are accompanied by a publication, you can gather a lot of information regarding experimental design and results from just this paper. Most often, the researchers already performed the most interesting research on this dataset and it is therefore a good exercise to try and reproduce their results. 
2. Alternatively you can come up with your own ideas and (biological) question(s) that you could try and answer given a dataset instead of redoing the published work.
    + This is of course more challenging and not suitable for all datasets.
    + You might notice that some publications only focus on a small set of genes instead of the whole transcriptome. For instance, when you perform an experiment on yeast where you want to measure the activity of genes involved in alcohol fermentation, researchers might only look at genes from the Glycolysis pathway. This leaves the other 6000+ yeast genes for you to explore and possibly come up with novel relations of gene expression and experimental setup.
    + If the analysis approach explained in the paper is not focusing on a pre-selected list of genes, depending on the experiment you might come up with comparisons not done in the original research. For instance, in an experiment where the maternal age (at birth) is correlated to autism in their offspring, the paternal age is also known but not addressed in the [publication](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE25507). This could be a subject of further research.
3. Another type of project is to evaluate different methods of either normalisation or statistical analysis to either confirm the published results or find novel genes involved in the experiment.
    + This can be viewed more as a technical research subject which is ok to pursue, however the final report should mainly concern the biological impact of your findings.
        - This means that when the accompanying publication shows very conclusive results, it will probably come down to *acknowledging* their results (therefore, you extend on point 1 from this list). Because with a very conclusive result you hope to find the same results and if this is not the case it might become hard to formulate a good conclusion in the end.
        - However, if the publication isn't very specific and only states a conclusion such as '*Benzene exposure shows increased risk of leukemia*' followed by a list of a few genes that *might* be involved, you could try to see if you can find other genes that *might* be involved by changing the analysis approach.
4. Although this last project goal has many risks involved and will need a very sound project proposal, it might result in the most interesting project. As shown before with the linked article, it is possible to combine data from multiple experiments.
    + You could for instance find two very related experiments (i.e. researching the effect of a certain drug) both measuring expression in different tissue types (i.e. liver and brain tissue). After analyzing both experiments, you could present a set of genes that show an effect in both tissues and - more interestingly - genes showing an effect in only one tissue.

The list above is a guideline to be kept in mind while browsing for suitable data sets and it will be extended in week three. Also, don't worry if some of the terms above are unclear, getting a good understanding on the used terminology is part of these first few weeks

## Instructions {#sra-instructions}

This chapter contains a number of - mostly open - questions and assignments, such as the one below. Your task is to answer these questions and turn in a report before the assignment deadline through Blackboard. The assignments of week three, performing literature research and writing a project proposal, built upon the assignments listed in this document. Deadline for all questions and assignments in this document (combined week one and two): **May 15, 12.30h**.

Create a single report containing the answers to the questions. Include any used references (articles, documents, books and internet addresses) that you've used, either in footnotes or as a last page in the report. As a general guideline, for (practical) assignments please treat your report as if it was a *lab journal*, so you can keep all your attempts in the final report instead of just the one with the final solution.

## The NCBI *Short Read Archive* {#ncbi-sra}

The first database(s) we are going to look at is the NCBI *Short Read Archive* and a few closely related databases. The SRA is a searchable database containing public, published experiments using NGS techniques (for older sequencing techniques, such as Sanger sequencing, there exists the [Trace Archive](http://www.ncbi.nlm.nih.gov/Traces/home/)).

***

```{r, echo=FALSE, results="asis"}
insert.q("SRA and RNA-Sequencing")
```

a. Explain in your own words - in the context of the SRA - what a **study** and an **experiment** is. Note; the figure below shows the actual layout (in tables) of the SRA database and the following section contains a very brief description of identifiers from these tables, but besides clarifying these descriptions, also explain their relation.
b. The Short Read Archive contains reads from different *NGS*-techniques. To use the SRA you will need to have a basic understanding of the data it hosts. For this project we are focusing on the **RNA-Seq** NGS technique. 
    + Summarize the process of performing an RNA-Seq experiment for a single biological sample with a focus on the data processing part.
    + Explain two types of processed output that you *could* get from an RNA-Seq experiment and explain how you can use these to perform further differential expression analysis.
c. Explain the term *Differentially Expressed Gene* (`DEG`) and include how or when a gene is labeled as a DEG in an RNA-seq analysis (note; there are many methods by which a DEG can be found, instead of listing them all try to explain one or at most two).

***

```{r SRA_db_schema, fig.width=4.5,echo=FALSE}
img <- readPNG("chapters/images/SRAdb.png")
grid.raster(img)
```

*A schematic overview of the `SRA` database schema*

## SRA Identifiers {#sra-identifiers}

As you probably have already visited the SRA website, this section contains a few informative tables taken from a knowledge base article called [`Understanding SRA Search Results`](http://www.ncbi.nlm.nih.gov/books/NBK56913/). These tables list the different kinds of identifiers you will encounter when searching the database for interesting and relevant data sets. For further information please refer to the [SRA Handbook at the NCBI Bookshelf](http://www.ncbi.nlm.nih.gov/books/NBK47528/). It is advised to at least browse through the contents list of this handbook so in case you come across unknown terms you know where to find further information on the subject.

The different `SRA` accession types:

| Accession Prefix | Accession Name | Definition | Example |
|-------|--------|---------------------------------------------|----------------------|
| SRA | SRA submission accession | The submission accession represents a virtual container that holds the objects represented by the other five accessions and is used to track the submission in the archive. | Since the SRA accession number is an artificial packaging construct, there is no example available since the SRA accession number has no specific response page |
| SRP | SRA study accession | A Study is an object that contains the project metadata describing a sequencing study or project. Imported from BioProject. | [LINK](http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?study=SRP000124) |
| SRX | SRA experiment accession | An Experiment is an object that contains the metadata describing the library, platform selection, and processing parameters involved in a particular sequencing experiment. | [LINK](http://www.ncbi.nlm.nih.gov/sra/SRX000193?report=full) |
| SRR | SRA run accession | A Run is an object that contains actual sequencing data for a particular sequencing experiment. Experiments may contain many Runs depending on the number of sequencing instrument runs that were needed. | [LINK](http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?cmd=viewer&m=data&s=viewer&run=SRR001030) |
| SRS | SRA sample accession | A Sample is an object that contains the metadata describing the physical sample upon which a sequencing experiment was performed. Imported from BioSample. | [LINK](http://www.ncbi.nlm.nih.gov/biosample/?term=119) |
| SRZ | SRA analysis accession | An analysis is an object that contains a sequence data analysis BAM file and the metadata describing the sequence analysis. | |

As you can see in the above table, all identifiers start with the letter **S**. However, not all identifiers found in the complete SRA database start with this letter. Other identifiers can either start with an **E** (links to the [EMBL-SRA](http://www.ebi.ac.uk/) database) or with a **D** (links to the [DDBJ-SRA](http://www.ddbj.nig.ac.jp/) database). The following two tables show the respective identifier types for the EMBL and DDBJ databases:

| Accession Prefix | Accession Name |
|----------|--------------------|
ERA | ERA submission accession |
ERP | ERA study accession |
ERX | ERA experiment accession |
ERR | ERA run accession |
ERS | ERA sample accession |
ERZ | ERA analysis accession |

| Accession Prefix | Accession Name |
|----------|--------------------|
DRA | DRA submission accession |
DRP | DRA study accession |
DRX | DRA experiment accession |
DRR | DRA run accession |
DRS | DRA sample accession |
DRZ | DRA analysis accession |

## Finding data sets of interest in the NCBI SRA

We will be using our SQL skills to search the SRA database. First, we need to get a copy of the *SRA*-metadata (everything except the sequencing data itself) which is available in a handy SQLite database.

Beware though, while the download is *only* Â±2GB, the extracted database is **27GB** in size(!) so instead of downloading the database to your own home directory you can access the centrally available version, either by using the following command from the terminal or by opening this file in the **SQLiteStudio** software (see [Appendix A](#sqlite-studio)):
```bash
sqlite3 /data/storage/databases/sradb/SRAmetadb.sqlite
```

```{r sra_db_loading, message=FALSE, echo=FALSE}
# Get the SRA-db file
sra_local <- '/Users/marcelk/Development/minor-bin/course/data/db/SRAmetadb.sqlite'
sra_bin   <- '/data/storage/databases/sradb/SRAmetadb.sqlite'
if(file.exists(sra_local)) {
  sqlfile <- sra_local
} else if(file.exists(sra_bin)) {
  sqlfile <- sra_bin
} else {
  # Download the file...
  sqlfile <- getSRAdbFile()
}

# Open an SQLite connection
sra_con <- dbConnect(SQLite(), sqlfile)
```

The database contains several tables which we can query and inspect:

```{r sra_db_contents, echo=FALSE}
# Tables
tables <- dbListTables(conn = sra_con)
pander(vector.to.table(tables, 5, "Tables"), caption = "Full listing of the tables in the SRA metadata DB")

# Columns in a table
fields <- dbListFields(conn = sra_con, name = "study")
pander(vector.to.table(fields, 7, "Columns"), caption = "Full listing of the columns in the 'study' table")
```

***

```{r, echo=FALSE, results="asis"}
insert.q("SRAdb")
```

Note that querying such a large database can take time, far more then you have previously experienced using relatively small databases.

a. Give the two queries or SQLite3 commands used to get the *list of tables* and the *columns in table `study`* (as shown in the tables above)
    + **NOTE**: The solution will not be performing a `SELECT` statement. However, SQLiteStudio seems to crash when trying the correct solution. Therefore it is adviced to use the terminal instead (see the command above) for these assignments (*a* and *b*).
b. Give the dimensions of the `experiment`, `run`, `sample`, `sra`, `study` and `submission` tables (rows and columns), you might need to search online for an efficient solution using the `pragma` command or you could:
    + use the command from (a) to get the number of columns and a
    + `SELECT COUNT(*)` query for the number of rows.

***

```{r study_table_contents, echo=FALSE, eval=FALSE}
# Unused for now
# the 'rs' object is called a Result Set which we use to store the result of a query
rs <- dbGetQuery(conn = sra_con, statement = "SELECT * FROM study LIMIT 3")
rs.trimmed <- apply(rs, 2, string.trim, 60)
pander(rs.trimmed, split.cells = 30,
       caption = "Top three rows, first three columns from the 'study' table (some fields are trimmed)")
```

```{sql, echo=FALSE, eval=FALSE}
# Table 2 - different study types
SELECT study_type AS StudyType, COUNT( * ) 
  AS Number FROM `study` GROUP BY study_type 
  ORDER BY Number DESC;

# Table 3 - instrument type
SELECT study_type AS StudyType, COUNT( * ) 
  AS Number FROM `study` GROUP BY study_type 
  ORDER BY Number DESC;
```

We can also show some statistics by using queries to count rows given a certain condition as shown with the two tables below:

```{r sra_example_queries, echo=FALSE, eval=TRUE}

# (we only use paste0() to split the query across multiple lines)
# Table 2
rs.studytype <- dbGetQuery(sra_con, "SELECT study_type AS StudyType, COUNT( * ) 
  AS Number FROM `study` GROUP BY study_type 
  ORDER BY Number DESC")

# Table 3
rs.instrument <- dbGetQuery(sra_con, "SELECT instrument_model AS 
  'Instrument Model', COUNT( * ) AS Experiments FROM `experiment` GROUP BY 
  instrument_model ORDER BY Experiments DESC LIMIT 10")

# Table 4 [solution for the following question] - Hidden
rs.strategy <- dbGetQuery(sra_con, "SELECT library_strategy AS 
  'Library Strategy', COUNT( * ) AS Runs FROM `experiment` 
  GROUP BY library_strategy ORDER BY Runs DESC LIMIT 10")
```

```{r, echo=FALSE, eval=TRUE}
pander(rs.studytype, caption = "Listing of the different study types")
pander(rs.instrument, caption = "Number of experiments run per instrument type (top 10)")
#pander(rs.strategy, caption = "Number of experiments run per strategy (top 5)")
```

```{r, echo=FALSE, results="asis"}
insert.q("RNA-Seq samples in the SRAdb")
```

a. Write an SQL query that lists the **number of experiments** run *per strategy* as listed in the `experiment` table. This is the same as the table above, except we're not counting the experiments run per *Instrument Model* but per *Strategy* (using the `study.library_strategy` column). Combine the `COUNT()`, `GROUP BY`, `ORDER BY` and `LIMIT` SQL functions to only show the **top 10** used strategies.
b. Answer the following by using queries on the `experiment` table:
    + How many RNA-Seq samples are available?
    + To how many *studies* do these samples belong (hint: use the `WHERE` (for the `library_strategy` column) and `DISTINCT` functions)?
        - If you look at the `study_accession` column, you will see that these are not unique. Therefore, you will need to count the number of unique study accessions.
    + **Optional (*advanced*)** (see the [w3resource website](http://www.w3resource.com/sqlite/arithmetic-operators.php) for examples on performing calculations *inside* SQL queries):
        - What is the minimum, maximum and average number of samples for all RNA-Seq *studies*? You can use multiple queries for this question, or sort the data to get the minimum and maximum values. For the average, you can use a `subquery` such as the example below:
        
        ```sql
        SELECT COUNT(*)/(SELECT COUNT(*) FROM ... WHERE ...) FROM ... WHERE ...
        ```

***

```{r, echo=FALSE, eval=FALSE}
# Solution, hidden
rs.strategy <- dbGetQuery(sra_con, "SELECT library_strategy AS 
   'Library Strategy', COUNT( * ) AS Runs FROM `experiment` 
   GROUP BY library_strategy ORDER BY Runs DESC LIMIT 10")
rs.rnaseq_samples <- dbGetQuery(sra_con, "SELECT COUNT(study_accession) FROM experiment 
                                WHERE library_strategy='RNA-Seq' limit 100")
rs.rnaseq_studies <- dbGetQuery(sra_con, "SELECT COUNT(DISTINCT study_accession) FROM experiment 
                                WHERE library_strategy='RNA-Seq' limit 100")
```

## Filtering results for RNA Sequencing studies {#filter-for-RNA_SEQ}

For the duration of this project we will be working exclusively with data from **RNA-Seq** experiments, so for future queries we can limit the results to this strategy only using the `WHERE library_strategy='RNA_Seq'` where-clause. As you would have seen in the previous question, there are almost `15000` RNA-Seq studies available in the SRA containing over `250000` individual samples, so instead of just browsing the full collection, we can search for interesting terms using basic queries (a more advanced method is shown later) and then filter these results on the sequencing technique used.

The following query shows the titles of all studies (including all *Library Strategies*) focused on cardiomyopathy by performing a text search in the `study.study_description` field with a `LIKE` statement (the `%` signs are wildcards):

```sql
SELECT study_title, study_accession, study_type FROM study 
  WHERE study_description LIKE '%cardiomyopathy%';
```

```{r, echo=FALSE, eval=TRUE}
query <- "SELECT study_title, study_accession, study_type FROM study 
                WHERE study_description LIKE '%cardiomyopathy%'"
rs <- dbGetQuery(sra_con, query)
```

```{r, echo=FALSE, eval=TRUE}
rs$study_title <- gsub("_", " ", rs$study_title)
rs.trimmed <- apply(rs, 2, string.trim, 80)
pander(rs.trimmed, caption="Studies focused on cardiomyopathy", split.cells = 40)
```

\newpage

```{r, echo=FALSE, results="asis"}
insert.q("Find RNA-Seq studies given a certain search term.")
```

In this assignment we will search for studies based on the RNA-Seq sequencing technology filtered on descriptions containing a search term of interest. Provide only the queries as answer and take a look at the tables below this question for expected example output.

a. We can combine the data from the `study` table with the `library_strategy` in the `experiment` table using an **`INNER JOIN`** to filter on studies using `RNA-Seq` technology. This requires the `INNER JOIN` comparing the `study_accession` fields from both tables, a `LIKE` statement to get the *cardiomyopathy* studies and a comparison on the `experiment.library_strategy` field to filter for *RNA-Seq* experiments. 
    + Besides the columns listed above, select at least the following columns and give them a better readable name using the `AS` function: `study.study_title`, `study.study_accession`, `study.study_type` and `study.study_description`.
    + Results should be grouped by `study.study_accession` since each study often consists of multiple experiment-runs.
    + Test the query using two search terms of choice using the `LIKE %term%` example shown above on the `study.study_description` column.
b. Extend the query above by adding a column called `Experiments` which is a count of the number of experiments for each of the found studies.


```{sql, echo=FALSE, eval=FALSE}
# solution for above question - hidden

SELECT study.study_title, study.study_accession AS 'Accession', 
  study.study_type, study.study_description AS 'Description', 
  experiment.library_strategy AS 'Strategy',
  COUNT(experiment.experiment_ID) AS 'Experiments'
  FROM `study` INNER JOIN experiment ON 
  study.study_accession=experiment.study_accession 
  WHERE study_description LIKE '%cardiomyopathy%' 
  AND experiment.library_strategy='RNA-Seq' 
  GROUP BY study.study_accession;
```

***

All RNA-Seq based studies containing *cardiomyopathy* or *lymphoblastic leukemia* in its description:

```{r, echo=FALSE, eval=TRUE}
get_studies <- function(connection, condition) {
  ## Simple function to get information on studies regarding a certain 'condition'
  query <- paste0("SELECT study.study_title, study.study_accession AS 'Accession', 
              study.study_description AS 'Description', 
              experiment.library_strategy AS 'Strategy',
              COUNT(experiment.experiment_ID) AS 'Experiments'
              FROM `study` INNER JOIN experiment ON 
              study.study_accession=experiment.study_accession 
              WHERE study_description LIKE '%", condition, "%' 
              AND experiment.library_strategy='RNA-Seq' 
              GROUP BY study.study_accession")
  rs <- dbGetQuery(connection, query)
  return(rs)
}

# Get the studies for two conditions
condition <- 'cardiomyopathy'
rs.cardio <- get_studies(sra_con, condition)
condition <- 'lymphoblastic leukemia'
rs.ALL <- get_studies(sra_con, condition)
```

```{r, echo=FALSE, eval=TRUE}
rs.cardio$study_title <- gsub("_", " ", rs.cardio$study_title)
rs.trimmed <- apply(rs.cardio, 2, string.trim, 50)
pander(rs.trimmed, split.cells = 40, 
       caption = "RNA-Seq studies related to 'cardiomyopathy' available in the SRA (search keyword: 'cardiomyopathy')")
```

```{r, echo=FALSE, eval=TRUE}
rs.trimmed <- apply(rs.ALL, 2, string.trim, 50)
pander(rs.trimmed, split.cells = 40, caption = "RNA-Seq studies related to ALL disease available in the SRA (search keyword: 'lymphoblastic leukemia')")
```

## Searching a large database with SQLite *Full Text Search* {#full-text-search}

In the previous question we used the standard SQL `LIKE` method of finding text matches in columns. When you look at the tables contained within the SRA database, you will find a number of tables annotated with `_ft_` which stands for the SQLite Full Text Search (**FTS**) extension ([SQLite FTS3 and FTS4 Extensions manual](https://www.sqlite.org/fts3.html)). The theory behind FTS is to complex to discuss here, but its purpose is to simplify and speed up text searches in large databases.

***

```{r, echo=FALSE, results="asis"}
insert.q("Full Text Search using `getSRA`")
```

Use **FTS** in one of the queries from the previous question. Note that there is no `study_ft` table so we use the `sra_ft` table which contains the same fields (actually, it is a *virtual table* combining the `study` and `experiment` tables). The table below this question shows the expected output when searching for `leukemia`.

a. List all columns from the `sra_ft` table
b. Implement FTS searching for one of the previously used search terms on the `sra_ft` table (only include the query in the report).
    + Look at the FTS manual linked above in chapter **1.4** for information on how to do Full Text Search. You only need to replace a single SQL function in your previous query to do this.
    + Note that you do not need to use a `JOIN` since all relevant fields are in a single table.

***

```{sql, echo=FALSE, eval=FALSE}
# Solution
# For instance, the queries above could be rewritten and performed on the `sra_ft` table 
# (contains all information also present in the `study` table) to find information on *leukemia* 
# studies by simply replacing the `LIKE` function with a `MATCH` FTS-enabled function:

SELECT study_title, study_accession AS 'Accession', 
  study_type, instrument_model, taxon_id, common_name,
  study_description AS 'Description', 
  library_strategy AS 'Strategy',
  COUNT(experiment_ID) AS 'Experiments'
  FROM `sra_ft`  
  WHERE study_description MATCH 'leukemia' 
  AND library_strategy='RNA-Seq' 
  GROUP BY study_accession;
```

```{r, echo=FALSE, eval=TRUE}
q <- "SELECT study_title, study_accession AS 'Accession', 
      study_type, instrument_model, taxon_id, common_name,
      library_strategy AS 'Strategy',
      COUNT(experiment_ID) AS 'Experiments'
      FROM `sra_ft`  
      WHERE study_description MATCH 'leukemia' 
      AND library_strategy='RNA-Seq' 
      GROUP BY study_accession"
rs <- dbGetQuery(sra_con, q)
rs$study_title <- gsub("_", " ", rs$study_title)
rs.trimmed <- apply(rs, 2, string.trim, 40)
pander(rs.trimmed, split.cells = 40, justify = 'left',
       caption = "Results from using FTS text search with 'leukemia' as keyword")
```

### Inspecting an SRA *study* {#sra-study}

Once we found a study we are interested in by searching through the `study` or `sra_ft` table given a certain keyword, the following step is to take a look at how this study is organized; i.e. how many experiments are performed resulting in how many samples and ultimately; what data is there to download.

As an example, we have found the `ERP013684` study accession in the list of the *Acute Lymphoblastic Leukemia* (ALL) RNA-Seq studies. The table above also states that there are several experiments associated with this study for which we can get the information as well using the query below. The result shows us the `sample_accession` for each sample as well as the part of the experiment each sample belongs to (i.e., cell-type, condition, etc.):

```sql
SELECT sample_accession, spot_length, experiment_attribute 
  FROM experiment WHERE study_accession='ERP013684';
```

```{r study_sample_details, echo=FALSE}
q <- "SELECT sample_accession, spot_length, experiment_attribute 
  FROM experiment WHERE study_accession='ERP013684';"
rs <- dbGetQuery(sra_con, q)
pander(rs, split.cells = 30, caption = "Sample details for study 'ERP013684'")
```

These results can also be found by searching for the study accession in the online SRA: [ERP013684](http://www.ncbi.nlm.nih.gov/sra/?term=ERP013684)

***

```{r, echo=FALSE, results="asis"}
insert.q("Experimental Setup")
```
Look at the table above and answer the following questions. These questions are not specific for this experiment and it is not required to actually read information regarding this experiment, it only concerns the *design* of the experiment. 

a. Look closely at the `experiment_attribute` column, what do you notice?
b. What could be the reason that 12 samples have been sequenced for this study?
c. Do you know what the correct term is for the observation you've made?
d. How would these samples be used in the ('downstream') data analysis?

***

Given the list of samples we can also get much more information on each of the individual samples by querying the `sra` table using the `sample_accession` column. For instance, we can get technical details on all samples of study `ERP013684`  using the following query:

```sql
SELECT platform, 
  ROUND(spots / 1e6) AS 'Spots (1e6)', 
  ROUND(bases / 1e+9, 1) AS 'Bases (1e9)', 
  ROUND(bases * 0.65 / 1e+9, 1) AS 'Bytes (GB)',
  instrument_model
  FROM sra WHERE study_accession='ERP013684';
```

```{r, echo=FALSE}
q <- "SELECT platform, 
      ROUND(spots / 1e6) AS 'Spots (1e6)', 
      ROUND(bases / 1e+9, 1) AS 'Bases (1e9)', 
      ROUND(bases * 0.65 / 1e+9, 1) AS 'Bytes (GB)',
      instrument_model
      FROM sra WHERE study_accession='ERP013684'"
rs <- dbGetQuery(sra_con, q)
pander(rs, caption = paste("Technical information regarding samples for study 'ERP013684'.",
                           "Note: the size in GB is estimated (0.65 giga-bases per giga-byte)"))
```

This detailed sample information (as well as the other content from the `sra` table) can also be found online by searching with the `sra.experiment_accession` field, for instance for the last sample in the table above: [ERX1269965](http://www.ncbi.nlm.nih.gov/sra/ERX1269965[accn]).


***

```{r, echo=FALSE, results="asis"}
insert.q("Sample Details")
```

a. Which online database hosts the data for the **ERX1269965** sample?
b. What was the read length for the RNA sequencing part? (You might need to perform a calculation)

***

## Raw Data Files {#raw-data}

As you now have seen from querying the SRAdb, the [**ERP013684**](http://www.ncbi.nlm.nih.gov/sra/?term=ERP013684) experiment dataset consists of a number of samples, each represented by a downloadable raw **Fastq** file which should sound familiar.

```{r ERX_download, fig.width=8, echo=FALSE}
img <- readPNG("chapters/images/ERX1269965_download.png")
grid.raster(img)
```

With these Fastq files we are able to perform all the analysis that we want. However, as you can see in the `Bytes (GB)` column of the table listing the samples above, the total raw data is **>100GB** in size! We do have the skills to download these raw data files, map them to the transcriptome of the organism and do further processing, as you have experienced using Galaxy last period. However, in most cases it would take too much time to properly process the raw files before we can start with the actual analysis which is the goal of this project. In some cases you are allowed to do this yourself as mentioned in the beginning of this document, but it is then preferred that there is also processed data available as supplementary files as a fallback.

### Processing Raw SRA Data {#process-raw-data}

This subject is part of the *Theory of Bioinformatics II* module and has been part of the previous *Genomic Analysis* course.

## Supplementary Data Files {#supp-data}

Besides the raw sequencing data we are especially interested in any supplementary data files included in the dataset. The following formats are often offered for download (please note that all files are offered as compressed `gzip` files, they can be unpacked using `gunzip file.gz`):

| Format | Description                                | Size              |
|--------|--------------------------------------------|-------------------|
| BED    | `Browser Enabled Data`; mostly used for displaying data (any kind of *feature*: introns, exons, genes, variants, reads, etc.) in a *genome-browser track*. Contents include chromosomal positions (required) and optional columns such as feature or track name, strand and a *score*.            | medium; between 1MB and 200MB for each file |
| BW     | `bigWig`; a format used for display of dense, continuous data that will be displayed in the Genome Browser as a graph               | medium; between MB and MB for each file |
| FA     | `FASTA`; a standard file format for storing (named) sequences. In the case of GEO it can be used for custom reference genomes or found genes or isoforms of known genes etc.                | small to large; between 10KB and 10GB for each file
| XLSX | `Excel` file format used for a wide variety of data. Usually it contains large tables listed as supplementary data in the published article (and doesn't always have to make sense without reading the article) or it could contain the RPKM/FPKM data for all genes (although this is most often stored in standard TXT files, see below). |  small; < 10 MB for each file
| TXT | `Text` file format most often used for storing Count data, FPKM, RPKM or TPM values in tab-delimited format. Data is sometimes exported from Excel which occasionally makes data unusable (for example, consider the file `GSE74868_ETS2_T72D_OE_Epi_RNAseq.txt.gz` that can be found for experiment [GSE74868](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE74868) | often small, but they can go up to 1GB for each file |

Further information on common bioinformatics file formats can be found at the [UCSC](https://genome.ucsc.edu/FAQ/FAQformat.html)

### Processing Supplementary Data Files {#process-supp-data}

This is the main subject of weeks 4 - 7 where we will focus on processing the actual expression data for finding Differentially Expressed Genes (DEGs), visualize expression information using various techniques, pathway analysis and Gene Ontology (GO) analysis. All these tasks will be performed in R using popular packages from the [Bioconductor](https://www.bioconductor.org) suite.

```{r, echo=FALSE, eval=FALSE}
# Do not include as we're not using R, yet..
dbDisconnect( sra_con )
sessionInfo()
```

## The NCBI *Gene Expression Omnibus* {#ncbi-geo}

Now that we have completed exploring the SRA database we can focus on finding a study of interest! Preferably you'd use a query combining the `RNA-Seq` `WHERE`-clause with a search string containing a keyword that you'd like to search on. Alternatively, you can search for `RNA-Seq` experiments and *browse* the titles of the experiments to see if there's anything you like working with.

Another alternative (easiest) is to use a web-browser for exploring datasets. One such repository with a large overlap of SRA studies (containing only the published/ curated studies) is the [NCBI Gene Expression Omnibus](https://www.ncbi.nlm.nih.gov/geo/) (GEO). This *repository* is primarily used to store microarray datasets and describe those experiments, linking to raw data, processed data and an accompanying publication. There are however many more sources of data browsable in the GEO, and for this project we will limit our searches to "*Expression profiling by high throughput sequencing*" for which over 13.000 experiments are listed. The [GEO Summary](https://www.ncbi.nlm.nih.gov/geo/summary) page shows all available data sources, click on the right *Expression profiling* link to get to the full table of relevant experiments.

Besides finding an experiment that you are interested in, there are some further requirements that you need to account for when browsing:

* The experiment must be published and the publication must be fully available, free or otherwise through the Hanze University library.
* For each *sample group*, a minimum of **three** replicates must be present. If one or more groups have less then three replicates, that group cannot be used (the rest of the data might still be usable).
* The available data must contain at least the **count** data.
  + Data is offered in multiple formats, always including the RAW data (reads), but also in further processed data such as FPKM, RPKM and TPM (see this [interesting blog-post](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) discussing the use of these data). The tools and R analysis libraries that we will use for the downstream analysis rely on unnormalized or unprocessed data which is the **count** data. These counts simply represent the number of reads mapped to a transcript. For manual analysis, these need to be normalized across samples (which has been done to get the FPKM, RPKM or TPM values) but will be done by the analysis software using the count data (unbiased).

Once you've found an experiment, write a mail to [m.kempenaar@pl.hanze.nl](mailto:m.kempenaar@pl.hanze.nl) where you link your experiment. Add your project partner as a CC. Once you receive a *go-ahead* you can start by reading the accompanying article and writing a project proposal.

## Creating a Project Proposal {#project-proposal}

In week three you are asked to present a short project proposal where you:

* Briefly explain the subject, methods, results and conclusion of the chosen project,
* describe the experimental design of the chosen experiment; how many samples and in how many groups are they divided (i.e. how many replicates per group)?
* Show what *your* plan is with the dataset, given the choices listed in the section about [Finding Public Data](#finding-public-data). Note that whatever choice you make, the first steps will most likely be the same leading to finding the *Differentially Expressed Genes* (DEGs). It is very difficult to plan your complete project based on what you read in the article and it is not expected to get a planning for the full remaining 6 weeks. You can however specify a bit more given what you've read in the article, such as trying to reproduce a certain figure or repeat a certain analysis step.

Summarize your project proposal on max. 1 A4 and, combined with the slides, are the final deliverables for this chapter.